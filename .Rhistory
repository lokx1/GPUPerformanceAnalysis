print(Texture_Rate)
###############################################################################
# Descriptive statistics
# Function to calculate median
calc_median <- function(x) {
m <- median(x)
data.frame(y = m, label = paste0("Median: ", round(m, 2)))
}
# Boxplot of Pixel_Rate
plot1 <- ggplot(gpu_KNN, aes(x = "Pixel Rate", y = Pixel_Rate)) +
geom_boxplot() +
stat_summary(fun.data = calc_median, geom = "text", vjust = -0.5) +
labs(title = "Boxplot of Pixel Rate") +
ylab("Frequency")
# Boxplot of Memory
plot2 <- ggplot(gpu_KNN, aes(x = "ROPs", y = ROPs)) +
geom_boxplot() +
stat_summary(fun.data = calc_median, geom = "text", vjust = -0.5) +
labs(title = "Boxplot of ROPs") +
ylab("Frequency")
# Boxplot of Memory_Bus
plot3 <- ggplot(gpu_KNN, aes(x = "TMUs", y = TMUs)) +
geom_boxplot() +
stat_summary(fun.data = calc_median, geom = "text", vjust = -0.5) +
labs(title = "Boxplot of TMUs") +
ylab("Frequency")
# Boxplot of Memory_Speed
plot4 <- ggplot(gpu_KNN, aes(x = "Texture Rate", y = Texture_Rate)) +
geom_boxplot() +
stat_summary(fun.data = calc_median, geom = "text", vjust = -0.5) +
labs(title = "Boxplot of Texture Rate") +
ylab("Frequency")
# Combine the plots
combined_plot <- plot_grid(plot1, plot2, plot3, plot4, ncol = 2)
# Display the combined plot
print(combined_plot)
# Plotting function for scatter plots
plot_scatter <- function(data, x_var, y_var) {
ggplot(data, aes_string(x = x_var, y = y_var)) +
geom_point() +
labs(x = x_var, y = y_var) +
theme_minimal()
}
# List of factors to plot against Memory_Bandwidth
factors <- c("PSU_Watt", "Max_Power", "Pixel_Rate", "ROPs", "TMUs", "Texture_Rate")
# Create a list to store the plots
plots <- lapply(factors, function(factor) {
plot_scatter(gpu_KNN, x_var = factor, y_var = "Memory_Bandwidth")
})
# Combine all plots into one image
multiplot <- cowplot::plot_grid(plotlist = plots, nrow = 2)
# Display the combined image
multiplot
plot_histogram_with_median <- function(data, x_var, title) {
median_val <- median(data[[x_var]], na.rm = TRUE)
ggplot(data, aes_string(x = x_var)) +
geom_histogram(binwidth = 50, fill = "skyblue", color = "black") +
geom_vline(xintercept = median_val, color = "red", linetype = "dashed", size = 1) + # Add median line
labs(x = x_var, y = "Frequency", title = title) +
theme_minimal()
}
# Create histograms for PSU_Watt and Max_Power with median
histograms_with_median <- list(
plot_histogram_with_median(gpu_KNN, "PSU_Watt", "Histogram of PSU Watt"),
plot_histogram_with_median(gpu_KNN, "Max_Power", "Histogram of Max Power")
)
# Combine the histograms into one image
combined_histogram_with_median <- cowplot::plot_grid(plotlist = histograms_with_median, ncol = 2)
# Display the combined image
print(combined_histogram_with_median)
###############################################################################
install.packages("car")
library(car)
traindata <- gpu_KNN[1:1672,]
testdata <- gpu_KNN[1673:3344,]
# train_model
train_model = lm(formula = Memory_Bandwidth ~  Max_Power + PSU_Watt + PSU_Amps + Pixel_Rate + ROPs + TMUs + Texture_Rate, data = gpu_KNN)
summary(train_model)
#test_model
predictions <- predict(train_model, newdata = testdata)
testdata["MemBanPredict"]<-predictions
#Plot Actual and Predicted
plot(testdata$Memory_Bandwidth, testdata$MemBanPredict, xlab = "Actual", ylab = "Predict")
abline(lm(testdata$MemBanPredict~testdata$Memory_Bandwidth))
#Checking assumption on train_model
residuals <- residuals(train_model)
#creates a histogram plot of residuals
hist(residuals, freq = FALSE, main = "Histogram of Residuals")
mu <- mean(residuals)
sigma <- sd(residuals)
curve(dnorm(x, mean = mu, sd = sigma), col = "blue", lwd = 2, add = TRUE)
# Create Q-Q plot
qqnorm(residuals)
qqline(residuals)
residuals <- residuals[residuals < 500]
hist(residuals, freq = FALSE, main = "Histogram of Residuals")
mu <- mean(residuals)
sigma <- sd(residuals)
curve(dnorm(x, mean = mu, sd = sigma), col = "blue", lwd = 2, add = TRUE)
# Create Q-Q plot
qqnorm(residuals)
qqline(residuals)
# Scatterplot Matrix
pairs(~Memory_Bandwidth + Max_Power + PSU_Watt + Pixel_Rate + ROPs + TMUs + Texture_Rate, data=traindata, main="Scatterplot Matrix")
# Plot residuals vs. fitted values
plot(fitted(train_model), residuals(train_model), main="Residuals vs Fitted", xlab="Fitted values", ylab="Residuals")
abline(h=0, col="red")
###############################################################################
# Ridge Regression
install.packages("caret")
library(caret)
install.packages("glmnet")
library(glmnet)
x_train <- model.matrix(Memory_Bandwidth ~ Max_Power + PSU_Watt + PSU_Amps + Pixel_Rate + ROPs + TMUs + Texture_Rate, data = traindata)[,-1]
y_train <- traindata$Memory_Bandwidth
x_test <- model.matrix(Memory_Bandwidth ~ Max_Power + PSU_Watt + PSU_Amps + Pixel_Rate + ROPs + TMUs + Texture_Rate, data = testdata)[,-1]
set.seed(123)
cv_ridge <- cv.glmnet(x_train, y_train, alpha = 0, type.measure = "mse", nfolds = 10)
best_lambda <- cv_ridge$lambda.min
predictions <- predict(cv_ridge, s = best_lambda, newx = x_test)
plot(testdata$Memory_Bandwidth, predictions, main = "Dự đoán so với Thực tế Ridge Regression",
xlab = "Giá trị Thực tế Memory Bandwidth", ylab = "Giá trị Dự đoán Memory Bandwidth",
pch = 19)
abline(0, 1, col = "red")
install.packages("VIM")
install.packages("cowplot")
install.packages("corrplot")
install.packages("stringr")
install.packages("corrplot")
install.packages("cowplot")
install.packages("VIM")
install.packages("stringr")
install.packages("glmnet")
install.packages("caret")
library(tidyverse)
library(ggplot2)
library(dplyr)    # alternatively, this also loads %>%
install.packages("stringr")
library(stringr)
install.packages("corrplot")
library(corrplot)
install.packages("cowplot")
library(cowplot)
###############################################################################
#DATA READING
#import .csv file
gpu_data <- read.csv("~/BACH KHOA/probality/All_GPUs.csv")
###############################################################################
#DATA CLEANING
#Standardize variables with units
#L2_Cache convert
L2_IntConvert <- function(input_string) {
pattern <- "^([0-9]+)KB(?:\\(x([0-9]+)\\))?$"
# Initialize the result vector
result <- vector("numeric", length(input_string))
# Iterate over each input string
for (i in seq_along(input_string)) {
# Get the current string
current_string <- input_string[i]
# Check for NA input
if (is.na(current_string)) {
result[i] <- NA
next
}
# Perform regex search and extract matches
matches <- regmatches(current_string, regexec(pattern, current_string))[[1]]
# If no match, set result to NA
if (length(matches) == 0) {
result[i] <- NA
next
}
# Extract the numeric part and optional multiplier
numeric_value <- as.integer(matches[2])
multiplier <- if (length(matches) > 2 && matches[3] != "") as.integer(matches[3]) else 1
result[i] <- numeric_value * multiplier
}
return(result)
}
ROPs_IntConvert <- function(input_string) {
pattern <- "^([0-9]+)(?:\\s*\\(x([0-9]+)\\))?$"
result <- vector("numeric", length(input_string))
for (i in seq_along(input_string)) {
# Get the current string
current_string <- input_string[i]
# Check for NA input
if (is.na(current_string)) {
result[i] <- NA
next
}
# Use regex to extract the numeric part and optional multiplier
matches <- regmatches(current_string, regexec(pattern, current_string))[[1]]
# If no match, return NA
if (length(matches) == 0) {
result[i] <- NA
next
}
# Convert the numeric part and optional multiplier (default to 1) and calculate the result
numeric_value <- as.integer(matches[2])
multiplier <- if (length(matches) > 2 && matches[3] != "") as.integer(matches[3]) else 1
result[i] <- numeric_value * multiplier
}
return(result)
}
gpu_data$Boost_Clock <- as.integer(gsub("\\D","",gpu_data$Boost_Clock))
gpu_data$Core_Speed <- as.integer(gsub("\\D","",gpu_data$Core_Speed))
gpu_data$Max_Power <- as.integer(gsub("\\D","",gpu_data$Max_Power))
gpu_data$Memory <- as.integer(gsub("\\D","",gpu_data$Memory))
gpu_data$Memory_Bandwidth <- as.numeric(gsub("[^0-9.]+","",gpu_data$Memory_Bandwidth))
gpu_data$Memory_Bus <- as.integer(gsub("\\D","",gpu_data$Memory_Bus))
gpu_data$Memory_Speed <- as.integer(gsub("\\D","",gpu_data$Memory_Speed))
gpu_data$Pixel_Rate <- as.integer(gsub("\\D","",gpu_data$Pixel_Rate))
gpu_data$Process <- as.integer(gsub("\\D","",gpu_data$Process))
gpu_data$Texture_Rate <- as.integer(gsub("\\D","",gpu_data$Texture_Rate))
gpu_data$L2_Cache <- L2_IntConvert(gpu_data$L2_Cache)
gpu_data$PSU_Watt <- str_extract(gpu_data$PSU,"\\d+(?= Watt)") %>% as.integer()
gpu_data$PSU_Amps <- str_extract(gpu_data$PSU, "\\d+(?= Amps)") %>% as.integer()
gpu_data$ROPs <- ROPs_IntConvert(gpu_data$ROPs)
#Deal with missing value
instances = nrow(gpu_data)
colname <- names(gpu_data)
gpu_data[gpu_data == "" | gpu_data == "\nUnknown Release Date "]<- NA
missing_count <- colSums(is.na(gpu_data)) * 100 / instances
print(missing_count)
missing_data <- data.frame(feature = colname, non_missing = 100 - missing_count, missing = missing_count)
missing_data %>%
pivot_longer(-feature) %>%
ggplot( aes(x = feature, y = value, fill = name)) +
geom_col(position = position_stack(vjust=1, reverse=TRUE)) +
theme(axis.text.x = element_text(angle = 90,hjust = 1, vjust = 0.3)) +
xlab("Features") +
ylab("Percentages") +
labs(fill = NULL)
desired_columns <- c("Core_Speed","L2_Cache","Max_Power","Memory","Memory_Bandwidth","Memory_Bus","Memory_Speed","Memory_Type","Notebook_GPU","Open_GL","PSU_Amps","PSU_Watt","Pixel_Rate","Process","ROPs","TMUs","Texture_Rate")
# Create a new dataset with only the specified columns
New_gpu_data <- subset(gpu_data, select = desired_columns)
# Delete rows with value <NA> in column Architecture
#New_gpu_data <- New_gpu_data %>%
#    filter(!is.na(Architecture))
install.packages("VIM")
library(VIM)
gpu_KNN <- kNN(New_gpu_data, k = 58)
gpu_KNN <- gpu_KNN[, !grepl("_imp$", names(gpu_KNN))]
#Correlation coefficient between variables
numeric_columns <- gpu_KNN[, sapply(gpu_KNN, is.numeric)]
numeric_columns <- gpu_KNN %>%
select_if(is.numeric)
library(dplyr)
numeric_columns <- gpu_KNN %>%
select_if(is.numeric)
cor_matrix <- cor(numeric_columns, use = "pairwise.complete.obs")
corrplot(cor_matrix, method = "color", type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45, addCoef.col = "black", number.cex = 0.6,
diag = FALSE, cl.pos = "b", cl.cex = 0.7)
#Data summary
Max_Power<-xtabs(~Max_Power,data=gpu_KNN)
print(Max_Power)
Memory_Bandwidth<-xtabs(~Memory_Bandwidth,data=gpu_KNN)
print(Memory_Bandwidth)
PSU_Amps<-xtabs(~PSU_Amps,data=gpu_KNN)
print(PSU_Amps)
PSU_Watt<-xtabs(~PSU_Watt,data=gpu_KNN)
print(PSU_Watt)
Pixel_Rate<-xtabs(~Pixel_Rate,data=gpu_KNN)
print(Pixel_Rate)
ROPs<-xtabs(~ROPs,data=gpu_KNN)
print(ROPs)
TMUs<-xtabs(~TMUs,data=gpu_KNN)
print(TMUs)
Texture_Rate<-xtabs(~Texture_Rate,data=gpu_KNN)
print(Texture_Rate)
###############################################################################
# Descriptive statistics
# Function to calculate median
calc_median <- function(x) {
m <- median(x)
data.frame(y = m, label = paste0("Median: ", round(m, 2)))
}
# Boxplot of Pixel_Rate
plot1 <- ggplot(gpu_KNN, aes(x = "Pixel Rate", y = Pixel_Rate)) +
geom_boxplot() +
stat_summary(fun.data = calc_median, geom = "text", vjust = -0.5) +
labs(title = "Boxplot of Pixel Rate") +
ylab("Frequency")
# Boxplot of Memory
plot2 <- ggplot(gpu_KNN, aes(x = "ROPs", y = ROPs)) +
geom_boxplot() +
stat_summary(fun.data = calc_median, geom = "text", vjust = -0.5) +
labs(title = "Boxplot of ROPs") +
ylab("Frequency")
# Boxplot of Memory_Bus
plot3 <- ggplot(gpu_KNN, aes(x = "TMUs", y = TMUs)) +
geom_boxplot() +
stat_summary(fun.data = calc_median, geom = "text", vjust = -0.5) +
labs(title = "Boxplot of TMUs") +
ylab("Frequency")
# Boxplot of Memory_Speed
plot4 <- ggplot(gpu_KNN, aes(x = "Texture Rate", y = Texture_Rate)) +
geom_boxplot() +
stat_summary(fun.data = calc_median, geom = "text", vjust = -0.5) +
labs(title = "Boxplot of Texture Rate") +
ylab("Frequency")
# Combine the plots
combined_plot <- plot_grid(plot1, plot2, plot3, plot4, ncol = 2)
# Display the combined plot
print(combined_plot)
# Plotting function for scatter plots
plot_scatter <- function(data, x_var, y_var) {
ggplot(data, aes_string(x = x_var, y = y_var)) +
geom_point() +
labs(x = x_var, y = y_var) +
theme_minimal()
}
# List of factors to plot against Memory_Bandwidth
factors <- c("PSU_Watt", "Max_Power", "Pixel_Rate", "ROPs", "TMUs", "Texture_Rate")
# Create a list to store the plots
plots <- lapply(factors, function(factor) {
plot_scatter(gpu_KNN, x_var = factor, y_var = "Memory_Bandwidth")
})
# Combine all plots into one image
multiplot <- cowplot::plot_grid(plotlist = plots, nrow = 2)
# Display the combined image
multiplot
plot_histogram_with_median <- function(data, x_var, title) {
median_val <- median(data[[x_var]], na.rm = TRUE)
ggplot(data, aes_string(x = x_var)) +
geom_histogram(binwidth = 50, fill = "skyblue", color = "black") +
geom_vline(xintercept = median_val, color = "red", linetype = "dashed", size = 1) + # Add median line
labs(x = x_var, y = "Frequency", title = title) +
theme_minimal()
}
# Create histograms for PSU_Watt and Max_Power with median
histograms_with_median <- list(
plot_histogram_with_median(gpu_KNN, "PSU_Watt", "Histogram of PSU Watt"),
plot_histogram_with_median(gpu_KNN, "Max_Power", "Histogram of Max Power")
)
# Combine the histograms into one image
combined_histogram_with_median <- cowplot::plot_grid(plotlist = histograms_with_median, ncol = 2)
# Display the combined image
print(combined_histogram_with_median)
###############################################################################
install.packages("car")
library(car)
traindata <- gpu_KNN[1:1672,]
testdata <- gpu_KNN[1673:3344,]
# train_model
train_model = lm(formula = Memory_Bandwidth ~  Max_Power + PSU_Watt + PSU_Amps + Pixel_Rate + ROPs + TMUs + Texture_Rate, data = gpu_KNN)
summary(train_model)
#test_model
predictions <- predict(train_model, newdata = testdata)
testdata["MemBanPredict"]<-predictions
#Plot Actual and Predicted
plot(testdata$Memory_Bandwidth, testdata$MemBanPredict, xlab = "Actual", ylab = "Predict")
abline(lm(testdata$MemBanPredict~testdata$Memory_Bandwidth))
#Checking assumption on train_model
residuals <- residuals(train_model)
#creates a histogram plot of residuals
hist(residuals, freq = FALSE, main = "Histogram of Residuals")
mu <- mean(residuals)
sigma <- sd(residuals)
curve(dnorm(x, mean = mu, sd = sigma), col = "blue", lwd = 2, add = TRUE)
# Create Q-Q plot
qqnorm(residuals)
qqline(residuals)
residuals <- residuals[residuals < 500]
hist(residuals, freq = FALSE, main = "Histogram of Residuals")
mu <- mean(residuals)
sigma <- sd(residuals)
curve(dnorm(x, mean = mu, sd = sigma), col = "blue", lwd = 2, add = TRUE)
# Create Q-Q plot
qqnorm(residuals)
qqline(residuals)
# Scatterplot Matrix
pairs(~Memory_Bandwidth + Max_Power + PSU_Watt + Pixel_Rate + ROPs + TMUs + Texture_Rate, data=traindata, main="Scatterplot Matrix")
# Plot residuals vs. fitted values
plot(fitted(train_model), residuals(train_model), main="Residuals vs Fitted", xlab="Fitted values", ylab="Residuals")
abline(h=0, col="red")
###############################################################################
# Ridge Regression
install.packages("caret")
library(caret)
install.packages("glmnet")
library(glmnet)
x_train <- model.matrix(Memory_Bandwidth ~ Max_Power + PSU_Watt + PSU_Amps + Pixel_Rate + ROPs + TMUs + Texture_Rate, data = traindata)[,-1]
y_train <- traindata$Memory_Bandwidth
x_test <- model.matrix(Memory_Bandwidth ~ Max_Power + PSU_Watt + PSU_Amps + Pixel_Rate + ROPs + TMUs + Texture_Rate, data = testdata)[,-1]
set.seed(123)
cv_ridge <- cv.glmnet(x_train, y_train, alpha = 0, type.measure = "mse", nfolds = 10)
best_lambda <- cv_ridge$lambda.min
predictions <- predict(cv_ridge, s = best_lambda, newx = x_test)
plot(testdata$Memory_Bandwidth, predictions, main = "Dự đoán so với Thực tế Ridge Regression",
xlab = "Giá trị Thực tế Memory Bandwidth", ylab = "Giá trị Dự đoán Memory Bandwidth",
pch = 19)
abline(0, 1, col = "red")
install.packages("VIM")
install.packages("cowplot")
install.packages("corrplot")
install.packages("stringr")
install.packages("cowplot")
install.packages("VIM")
install.packages("stringr")
install.packages("corrplot")
install.packages("glmnet")
install.packages("caret")
plot(testdata$Memory_Bandwidth, predictions, main = "Predicted vs Actual Value using Ridge Regression",
xlab = "Actual Memory Bandwidth Value", ylab = "Predicted Memory Bandwidth Value",
pch = 19)
abline(0, 1, col = "red")
print(predictions)
x_train <- model.matrix(Memory_Bandwidth ~ Max_Power + PSU_Watt + PSU_Amps + Pixel_Rate + ROPs + TMUs + Texture_Rate, data = traindata)[,-1]
y_train <- traindata$Memory_Bandwidth
x_test <- model.matrix(Memory_Bandwidth ~ Max_Power + PSU_Watt + PSU_Amps + Pixel_Rate + ROPs + TMUs + Texture_Rate, data = testdata)[,-1]
set.seed(123)
cv_ridge <- cv.glmnet(x_train, y_train, alpha = 0, type.measure = "mse", nfolds = 10)
best_lambda <- cv_ridge$lambda.min
predictions <- predict(cv_ridge, s = best_lambda, newx = x_test)
plot(testdata$Memory_Bandwidth, predictions, main = "Predicted vs Actual Value using Ridge Regression",
xlab = "Actual Memory Bandwidth Value", ylab = "Predicted Memory Bandwidth Value",
pch = 19)
abline(0, 1, col = "red")
summary(predictions)
summary(testdata)
predictions <- predict(cv_ridge, s = best_lambda, newx = x_train)
sse <- sum((predictions - y_train)^2)
sst <- sum((y_train - mean(y_train))^2)
r_squared <- 1 - sse / sst
# Tạo báo cáo tùy chỉnh
cat("Coefficients:\n")
print(coef_ridge)
coef_ridge <- predict(cv_ridge, s = "lambda.min", type = "coefficients")
predictions <- predict(cv_ridge, s = best_lambda, newx = x_train)
sse <- sum((predictions - y_train)^2)
sst <- sum((y_train - mean(y_train))^2)
r_squared <- 1 - sse / sst
# Tạo báo cáo tùy chỉnh
cat("Coefficients:\n")
print(coef_ridge)
cat(sprintf("\nResidual standard error: %.2f on %d degrees of freedom\n", sqrt(sse/nrow(traindata)), nrow(traindata) - length(coef_ridge)))
cat(sprintf("Multiple R-squared: %.4f\n", r_squared))
model <- lm(formula = Memory_Bandwidth ~  Max_Power + PSU_Watt + PSU_Amps + Pixel_Rate + ROPs + TMUs + Texture_Rate, data = traindata)
if (!requireNamespace("ggplot2", quietly = TRUE)) {
install.packages("ggplot2")
}
# Load ggplot2 package
library(ggplot2)
# Check for homoscedasticity using residuals vs fitted values plot
residuals_plot <- ggplot(data = traindata, aes(x = fitted(model), y = resid(model))) +
geom_point() +
geom_smooth(method = "loess", se = FALSE, linetype = "dashed") +
labs(x = "Fitted Values", y = "Residuals") +
ggtitle("Residuals vs Fitted Values") +
theme_minimal()
print(residuals_plot)
# Perform Breusch-Pagan test to check for homoscedasticity
bp_test <- ncvTest(model)
print(bp_test)
train_model = lm(formula = Memory_Bandwidth ~  Max_Power + PSU_Watt + PSU_Amps + Pixel_Rate + ROPs + TMUs + Texture_Rate, data = traindata)
summary(train_model)
#test_model
predictions <- predict(train_model, newdata = testdata)
testdata["MemBanPredict"]<-predictions
#Plot Actual and Predicted
plot(testdata$Memory_Bandwidth, testdata$MemBanPredict, xlab = "Actual", ylab = "Predict")
abline(lm(testdata$MemBanPredict~testdata$Memory_Bandwidth))
# Plot residuals vs. fitted values
plot(fitted(train_model), residuals(train_model), main="Residuals vs Fitted", xlab="Fitted values", ylab="Residuals")
abline(h=0, col="red")
#Checking assumption on train_model
residuals <- residuals(train_model)
#creates a histogram plot of residuals
hist(residuals, freq = FALSE, main = "Histogram of Residuals")
mu <- mean(residuals)
sigma <- sd(residuals)
curve(dnorm(x, mean = mu, sd = sigma), col = "blue", lwd = 2, add = TRUE)
# Create Q-Q plot
qqnorm(residuals)
qqline(residuals)
#test_model
predictions <- predict(train_model, newdata = testdata)
testdata["MemBanPredict"]<-predictions
#Plot Actual and Predicted
plot(testdata$Memory_Bandwidth, testdata$MemBanPredict, xlab = "Actual", ylab = "Predict")
abline(lm(testdata$MemBanPredict~testdata$Memory_Bandwidth))
# Boxplot of Pixel_Rate
plot1 <- ggplot(gpu_KNN, aes(x = "Pixel Rate", y = Pixel_Rate)) +
geom_boxplot() +
stat_summary(fun.data = calc_median, geom = "text", vjust = -0.5) +
labs(title = "Boxplot of Pixel Rate") +
ylab("Value")
# Boxplot of Memory
plot2 <- ggplot(gpu_KNN, aes(x = "ROPs", y = ROPs)) +
geom_boxplot() +
stat_summary(fun.data = calc_median, geom = "text", vjust = -0.5) +
labs(title = "Boxplot of ROPs") +
ylab("Value")
# Boxplot of Memory_Bus
plot3 <- ggplot(gpu_KNN, aes(x = "TMUs", y = TMUs)) +
geom_boxplot() +
stat_summary(fun.data = calc_median, geom = "text", vjust = -0.5) +
labs(title = "Boxplot of TMUs") +
ylab("Value")
# Boxplot of Memory_Speed
plot4 <- ggplot(gpu_KNN, aes(x = "Texture Rate", y = Texture_Rate)) +
geom_boxplot() +
stat_summary(fun.data = calc_median, geom = "text", vjust = -0.5) +
labs(title = "Boxplot of Texture Rate") +
ylab("Value")
# Combine the plots
combined_plot <- plot_grid(plot1, plot2, plot3, plot4, ncol = 2)
print(combined_plot)
abline(0,1,col"red")
abline(0,1,col="red")
plot(abline(0,1,col="red"))
